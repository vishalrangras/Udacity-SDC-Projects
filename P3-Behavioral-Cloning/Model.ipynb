{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Loading CSV File\n",
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)\n",
    "correction = 0.2\n",
    "def generator(samples, batch_size=16):\n",
    "    num_samples = len(samples)\n",
    "    correction = 0.2\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            measurements = []\n",
    "            for batch_sample in batch_samples:\n",
    "                for i in range(3):\n",
    "                    name = './data/IMG/'+batch_sample[i].split('/')[-1]\n",
    "                    image = cv2.imread(name)\n",
    "                    measurement = float(batch_sample[3])\n",
    "                    if i == 1:\n",
    "                        measurement = measurement + correction\n",
    "                    elif if == 2:\n",
    "                        measurement = measurement - correction\n",
    "                    images.append(image)\n",
    "                    measurements.append(measurement)\n",
    "\n",
    "            #Data Augmentation\n",
    "            #Flipping the images\n",
    "            #Multiplying the steering angle measurement with -1\n",
    "            augmented_images, augmented_measurements = [], []\n",
    "            for image, measurement in zip(images, measurements):\n",
    "                augmented_images.append(image)\n",
    "                augmented_measurements.append(measurement)\n",
    "                augmented_images.append(cv2.flip(image,1))\n",
    "                augmented_measurements.append(measurement*-1.0)\n",
    "\n",
    "            #Converting the list into numpy arrays\n",
    "            #This constitutes Features and Labels\n",
    "            X_train = np.array(augmented_images)\n",
    "            y_train = np.array(augmented_measurements)\n",
    "\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=16)\n",
    "validation_generator = generator(validation_samples, batch_size=16)\n",
    "\n",
    "#Model Architecture starts from here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "import keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Preprocessing the images\n",
    "#Normalization and Mean Centre\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "\n",
    "#Image cropping\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "\n",
    "#Nvidia Model starts here\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,subsample=(2,2), activation=\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "#history_object = model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=7, verbose=1)\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch=len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
